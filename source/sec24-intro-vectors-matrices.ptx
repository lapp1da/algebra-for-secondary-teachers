<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec24-intro-vectors-matrices" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Introduction to Vectors and Matrices</title>

  <introduction>
    <p>
      Imagine you are standing in an unfamiliar forest and seeking a way out.  
      You can see the sun and know the approximate time of day and know that your parked 
      car is on the northmost edge of the forest.  How do you navigate your way toward your car?  
      Do you need to know your exact location or do you simply need to identify a direction you 
      need to go from your current location?  This question involves the idea of a direction and "magnitude" 
      meaning the length of your path.  This is one use of objects called <em>vectors</em>.  While this 
      interpretation of vector is a commonly use, there are other ways vectors can describe other phenomena.  
      Here we will examine the concept of vectors as well as <em>matrices</em> (a kind of super vector) that 
      can store information that vectors can use.
    </p>

  </introduction>

  <subsection xml:id="subsec-model-moving-worlds">
    <title>Modeling Data and Moving Between Worlds</title>

  <introduction>

    <p>
      The Common Core State Standards include the teaching of vectors and matrices, although not all aspects of 
      these concepts are expected for all student who graduate high school.  Many of the more complex uses 
      of vectors and matrices are left for those planning to enter mathematically rigorous fields of study 
      at the university level.  The CCSS denote this by placing a (+) next to the standard that is not intended 
      for all students (see <xref ref="fig-ccss-vectors-matrices"/>).
    </p>

    <p>
      <figure xml:id="fig-ccss-vectors-matrices">
        <caption>CCSS: Vectors and Matrices</caption>
        <image source="images/ccss-vectors-matrices.png" width="90%">
          <shortdescription>CCSS: Vectors and Matrices</shortdescription>
        </image>
      </figure>
    </p>

    <p>
      <activity>
        <introduction>
          <p>
            Jason is teaching an Algebra 2 class and is introducing a unit on vectors and matrices.  To 
            motivate the topics, he has created a project where students are working for a company that sells 
            products to other companies and must manage the relationship between the price they charge for 
            their products and the revenue they can generate from sales.  He begins class by posing the task.
          </p>

          <p>
            <em>Jason</em> : Today we are going to deal with a problem that many businesses face.  How do you 
            set prices for your products and what effects do those decisions have on the revenue you get 
            from your consumers?  Suppose we have a company that sells T-shirts to three main stores: 
            <em>Total Tees</em>, <em>T-Riffic</em>, and <em>T-Rex</em>.  Our company mass produces four basic 
            prints of T-shirts.  Let's call them <em>T1</em>, <em>T2</em>, <em>T3</em>, and <em>T4</em>.  
            On the board, I have put the orders for each type of T-shirt for each of the three stores.
          </p>
          <p>
            <figure xml:id="fig-tshirt-orders">
              <caption>Jason's List of T-Shirt Orders</caption>
              <image source="images/tshirt-orders.png" width="90%">
                <shortdescription>Jason's List of T-Shirt Orders</shortdescription>
              </image>
            </figure>
          </p>

          <p>
            We want to be able to work with various options of pricing for the different shirts as the demand 
            warrants.  For example, if one particular print gaiin popularity, we might want to raise its cost 
            to the stores since there is higher demand.  If another print is less popular, we may want to lower 
            the price we charge the stores to encourage more demand.  Long-story-short, we want to develop a 
            way to calculate the revenue we get from each store as we tweak the prices we charge for the 
            different shirts.  Does anyone have any questions?  Yeah, Bri?
          </p>

          <p>
            <em>Bri</em> : So what you're saying is that if we have the prices, we want to be able to quickly 
            find the total amount we get from each store?  With the orders you put on the board?
          </p>

          <p>
            <em>Jason</em> : Yep.  You got it!
          </p>

          <p>
            <em>Nic</em> : What if the orders change?
          </p>

          <p>
            <em>Jason</em> : Excellent question!  Let's just assume the orders stay the same here and we are just 
            messing with the prices for now.  Make a note, though, Nic, and we'll come back to your idea later.
          </p>

          <p>
            <em>Rosa</em> : Can we have some prices to start?  I'd like to have some prices so I can do some 
            calculations to see what's happening.
          </p>

          <p>
            <em>Jason</em> : OK, how about saying that we charge $12 for T1, $9 for T2, $10 for T3, and $8 for 
            T4.  Will that work?
          </p>

          <p>
            <em>Rosa</em> : Thanks.  That'll give us somewhere to start.
          </p>

          <p>
            <em>Jason</em> : Great, now go ahead in your groups and talk about how you might go about this.  
            Feel free to use any tools we usually have in class like your computer or CAS.
          </p>

          <p>
            [<em>Jason allows the students about 20 minutes to start talking about ways to handle the situation. 
              As he circulates, Jason notices Mia's group working with their CAS to take a functional approach 
              to deal with problem.  He makes a note to have Mia share when the class comes back together for 
              discussion.  Jason also notes that Nic's group seems to holding onto Nic's earlier comment about 
              changing orders and have started to explore the problem with a spreadsheet.  Jason was happy to 
              see Nic's group's approach as he thinks it will help him transition eventually to defining 
              multiplication between a matrix and a vector.  After time for exploration, Jason brings the class 
              back together to share ideas.
            </em>]
          </p>

          <p>
            <em>Jason</em> : So what did you try?  Anyone want to go first?  Yeah, Mia?
          </p>

          <p>
            <em>Mia</em> : Well, we kinda used our CAS to define functions for each store.  We can put the 
            in the functions and it gives us the money we get froom them.
          </p>

          <p>
            <em>Jason</em> : The revenue?
          </p>

          <p>
            <em>Mia</em> : Yeah, I guess.
          </p>

          <p>
            <em>Jason</em> : Can I show your calculator on the display?
          </p>

          <p>
            <em>Mia</em> : Yeah, I'm logged in.
          </p>

          <p>
            [<em>Jason displays Mia's calculator through the wireless network.
            </em> (see <xref ref="fig-mia-cas-define"/>)]
          </p>

          <p>
            <figure xml:id="fig-mia-cas-define">
              <caption>Mia's Group's Defined Functions</caption>
              <image source="images/mia-cas-define.png" width="70%">
                <shortdescription>Mia's Group's Defined Functions</shortdescription>
              </image>
            </figure>
          </p>

          <p>
            <em>Jason</em> : Tell us what everything is.
          </p>

          <p>
            <em>Mia</em> : Well, the tt is for orders for Totally Tees, tr is for T-Riffic, and tx is for T-Rex.  
            We just used w,x,y, and z for the placeholders for the prices so we can just enter them in the 
            functions.
          </p>

          <p>
            <em>Jason</em> : Great idea.  Can you show us how you would calculate the revenue.
          </p>

          <p>
            <em>Mia</em> : Sure, just put in 12, 9, 10, and 8 in the functions and you get ...
          </p>

          <p>
            <figure xml:id="fig-mia-cas-prices">
              <caption>Mia's Group's Defined Functions</caption>
              <image source="images/mia-cas-prices.png" width="70%">
                <shortdescription>Mia's Group's Functions with Prices</shortdescription>
              </image>
            </figure>
          </p>

        </introduction>
      </activity>
    </p>
  
  
    <p>
    In this section we will look at linear algebra as a way to encode information 
    and operate on it allowing us to move between different sets of information.  To this end, we 
    will define how <em>matrices</em> and <em>vectors</em> are operated on with binary operations like addition 
    and multiplication.  While multiplication of matrices may seem weird at first, you will see that it is 
    defined as it is for convenience in manipulating data and transforming different types of values into 
    other computed values based on them.  We begin by considering a case where we want to move between 
    a pricing scheme and the revenue it generates for three different companies with three different 
    sets of orders of our products.
  </p>
  <p>
    To accomplish this, we will use constructs created to deal with objects that contain multiple entries.  
    In the scenario we are using where companies place orders for products, we want to encode the numerical 
    values for the orders organizing them according to the product and company placing the order.  Here 
    just want to reduce the information to an array of values and so we define a <em>matrix</em> as an 
    array of values (or objects) consisting of rows and columns.  We typically contain these values with 
    brackets or parentheses like:
    <me>
       \begin{bmatrix}
14\amp 9\amp 34\amp 41\\
32\amp 7\amp 12\amp 52\\
21\amp 8\amp 5\amp 23
\end{bmatrix} 
\text{or}
  \begin{pmatrix}
14\amp 9\amp 34\amp 41\\
32\amp 7\amp 12\amp 52\\
21\amp 8\amp 5\amp 23
\end{pmatrix}
</me>
    In the matrices above, the columns could represent the numbers of each of four products being ordered 
    and the rows could represent the three different companies placing the orders (see the table of orders 
    for this situation given in <xref ref="product-orders" />).
  </p>
  <p> 
    We also define a <em>vector</em> as matrix with a single column such as 
    <m>
    \mathbf{v}=\begin{bmatrix}
    2\\0\\-3
    \end{bmatrix}
    </m> 
    or 
    <m>
    \mathbf{w}=\begin{bmatrix}
    1\\7\\-1\\4
    \end{bmatrix}
    </m>. 
    Note that we are using boldface to denote the names of the vectors for convenience to distinguish them from 
    numerical objects that we call <em>scalars</em>.  In a text like this, using boldface makes sense 
    in print, but typically, in written work, we use a harpoon over the name since boldface is not practical 
    with a pen.  In this case, we would write the names as <m>\overset{\rightharpoonup}{v}</m> or 
    <m>\overset{\rightharpoonup}{w}</m> respectively.
  </p>
  <p>
    You may have encountered vectors before in geometry or physics.  We will go into greater detail later with 
    respect to the geometric interpretation, but for now, the behavior remains the same in that operations 
    still work as they do in geometry and physics.  Essentially, vectors consist of <em>components</em> 
    so that when the vectors are added, we simply add the components.
    </p>
    <p>
    <definition xml:id="def-vector-add">
      <statement>
          <p>
            If <m>\mathbf{v}</m> and <m>\mathbf{u}</m> are vectors, we define vector addition as adding the 
            vectors component by component.  Note that the vectors must be of the same dimension.
          <me>
            \mathbf{v}+\mathbf{u} = 
             \begin{bmatrix}
            v_1\\
             v_2\\
             \vdots\\
             v_n
             \end{bmatrix} +
             \begin{bmatrix}
             u_1\\
              u_2\\
             \vdots\\
             u_n
             \end{bmatrix} =
             \begin{bmatrix}
             v_1+u_1\\
             v_2+u_2\\
             \vdots\\
             v_n+u_n
             \end{bmatrix}
            </me>
        </p>
      </statement>
    </definition>
    </p>
    <p>
    For example, suppose we have the two vectors in <m>\mathbb{R}^3</m>,  
    <m>
    \begin{bmatrix}
    1\\-5\\2
    \end{bmatrix}
    \text{and}
    \begin{bmatrix}
    2\\1\\7
    \end{bmatrix}
    </m>.  Adding these would result in 
    <m>
       \begin{bmatrix}
    1\\-5\\2
    \end{bmatrix} +
    \begin{bmatrix}
    2\\1\\7
    \end{bmatrix} =
    \begin{bmatrix}
    3\\-4\\9
    \end{bmatrix}
    </m>.
  </p>
  <p>
    The other basic operation we can do with vectors is to <em>scale</em> them (geometrically make them longer 
    or shorter or in the case of negative values, make them go in the opposite direction).  For this reason, 
    when we multiply the vector by a numerical value, we call that value a <em>scalar</em>.  For example, 
    <me>
    2\cdot \begin{bmatrix}
    -1\\3\\5
    \end{bmatrix} =
    \begin{bmatrix}
    -2\\6\\10
    \end{bmatrix}
    </me>
    In essence, we scaled the vector by a factor of 2.
  </p>
  <p>
    <definition xml:id="def-scalar-mult">
      <statement>
        <p>
          In general, we can define scalar multiplication of a vector as 
        <men>
        c \cdot \mathbf{v} =  c\cdot \begin{bmatrix}
        v_1\\
        v_2\\
        \vdots\\
        v_n
       \end{bmatrix} =
       \begin{bmatrix}
        cv_1\\
        cv_2\\
        \vdots\\
        cv_n
        \end{bmatrix}
        </men>
        where <m>c\in \mathbb{R}</m>.
        </p>
      </statement>
    </definition>
    
  </p>
  <p>
Combining scalar multiplication with vector addition, we get
<men>
      c_1\cdot \mathbf{v}+c_2\cdot \mathbf{u} = 
      c_1\cdot \begin{bmatrix}
      v_1\\
      v_2\\
      \vdots\\
      v_n
      \end{bmatrix} +
      c_2\cdot \begin{bmatrix}
      u_1\\
      u_2\\
      \vdots\\
      u_n
      \end{bmatrix} =
      \begin{bmatrix}
      c_1 v_1+c_2 u_1\\
      c_1 v_2+c_2 u_2\\
      \vdots\\
      c_1 v_n+c_2 u_n
      \end{bmatrix}
    </men>
    We can use these <em>linear combinations</em> applying them to our previous scenario for moving 
    between price of materials and the revenue they generate.
  </p>

<p>
  <activity xml:id="act-basic-vector-operations">
    <title>Working with Vectors</title>
    <introduction>
      <p>
        As we begin to work with vectors, we should examine how basic operations with them work both numberically 
        and geometrically.  Here we will first look at vector addition and then scalar multiplication.
      </p>
    </introduction>

    <task>
      <statement>
        <p>
          In <xref ref="def-vector-add"/>, we defined an addition for vectors based on component-wise addition.  
          Consider the vectors in <m>\mathbb{R}^2</m>, <m>\mathbf{v}=\begin{bmatrix} 2\\1 \end{bmatrix}</m> and 
          <m>\mathbf{w}=\begin{bmatrix} 1\\3 \end{bmatrix}</m>.  Numerically add these two vectors in two ways, 
          first <m>\mathbf{v}+\mathbf{w}</m> and then <m>\mathbf{w}+\mathbf{v}</m>.  Give your result in each 
          case and describe what you notice.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          On the grid in <xref ref="fig-grid-vector-add"/>, plot both <m>\mathbf{v}</m> and <m>\mathbf{w}</m> 
          as directed line segments (i.e. arrows).  Also plot the results you obtained for 
          <m>\mathbf{v}+\mathbf{w}</m> and <m>\mathbf{w}+\mathbf{v}</m>.  In your groups, discuss how you might 
          interpret movement from the origin along <m>\mathbf{v}</m> and <m>\mathbf{w}</m> to arrive at the 
          location of <m>\mathbf{v}+\mathbf{w}</m> and <m>\mathbf{w}+\mathbf{v}</m>.  How is the interpretation 
          of movement different depending on whether you are using <m>\mathbf{v}+\mathbf{w}</m> or 
          <m>\mathbf{w}+\mathbf{v}</m>?  Sketch the directed movement as a combination of two vectors (arrows) 
          for each case.
        </p>
        <p>
        <figure xml:id="fig-grid-vector-add">
          <caption>Grid for Vector Addition</caption>
          <image source="images/grid-blank-1-1.png" width="60%">
          <shortdescription>Grid for Adding Vectors</shortdescription>
        </image>
        </figure>
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          In <xref ref="def-scalar-mult"/>, we defined scalar multiplication for vectors based on component-wise 
          multiplication by the same scalar (number).  Consider the vector in <m>\mathbb{R}^2</m>, 
          <m>\mathbf{v}=\begin{bmatrix} 2\\-1 \end{bmatrix}</m>.  Numerically multiply this vector by the 
          scalars <m>c=-1</m>, <m>c=3</m>, and <m>c=-2</m>.  Give your result in each case.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          On the grid in <xref ref="fig-grid-scalar-mult"/>, plot <m>\mathbf{v}</m> and <m>c \cdot \mathbf{v}</m> 
          as directed line segments (i.e. arrows) for each value of <m>c</m>.  Describe what you notice about 
          all of these results.
        </p>
        <figure xml:id="fig-grid-scalar-mult">
          <caption>Grid for Vector Addition</caption>
          <image source="images/grid-blank-1-1.png" width="60%">
          <shortdescription>Grid for Adding Vectors</shortdescription>
        </image>
        </figure>
        <p>
          
        </p>
      </statement>
    </task>
    
    
  </activity>
</p>

</introduction>

<subsubsection xml:id="sec-Linear-Comb-Data">
  <title>Linear Combinations and Dealing with Data</title>


    <p>
      Continuing our scenario from the introduction.  Suppose that a supplier provides four different products with 
      prices, <m> p_1, p_2, p_3, p_4 </m>, to three companies.  One thing we may want to do is to play with pricing
        schemes and look at the generated revenue we would get from each of the three companies.  
        Suppose we have orders from the three companies for each of our four products as given in the table below.
    </p>
       <p>
        <table xml:id="product-orders">
  <title>Product Orders</title>
  <tabular halign="center">
    <row header="yes" bottom="minor">
      <cell>Clients</cell>
      <cell>Product 1</cell>
      <cell>Product 2</cell>
      <cell>Product 3</cell>
      <cell>Product 4</cell>
    </row>
    <row>
      <cell>Company 1</cell>
      <cell>14</cell>
      <cell>9</cell>
      <cell>34</cell>
      <cell>41</cell>
    </row>
    <row>
      <cell>Company 2</cell>
      <cell>32</cell>
      <cell>7</cell>
      <cell>12</cell>
      <cell>52</cell>
    </row>
    <row>
      <cell>Company 3</cell>
      <cell>21</cell>
      <cell>8</cell>
      <cell>5</cell>
      <cell>23</cell>
    </row>
  </tabular>
</table>
       </p>
  <p>
    <activity xml:id="act-prices-vectors-revenue">
      <title >Prices, Vectors, and Revenue</title >
      <introduction>
      <p>
        Consider the scenario given above for the orders by three companies for four different products.
      </p>
      </introduction>

      <task>
      <statement>
      <p>
        Thinking of the four <term>Products</term> from <xref ref="product-orders"/> as each being a vector where the entries 
        of the vector store the orders made for each of the three companies, express this information as a 
        set of four vectors in <m>\mathbb{R}^3</m>.
      </p>
      </statement>
      <answer>
      <p>
        Since there are four <term>Products</term>, we can express the orders from the three companies for 
        each <term>Product</term> as an ordered triple (or vector) containing three entries (one for each company) 
        for that product.  This would give us a set of four vectors:
        <me>
        \left\{ \begin{bmatrix}
        14\\32\\21
        \end{bmatrix}
        ,\begin{bmatrix}
        9\\7\\8
        \end{bmatrix}
        ,\begin{bmatrix}
        34\\12\\5
        \end{bmatrix}
        ,\begin{bmatrix}
        41\\52\\23
        \end{bmatrix}
        \right\}
        </me>
      </p>
      </answer>
      </task>

      <task>
      <statement>
      <p>
        If Product 1 is priced at $12, Product 2 is priced at $9, Product 3 is priced at $15, 
        and Product 4 is priced at $7, using these prices for each of the four Products in the table as scalars, 
        write a linear combination of the vectors from your set from part (a) that when added will give a 
        vector in <m>\mathbb{R}^3</m> that represents the revenue generated from each company.  How much 
        did you collect from each company?  Feel free to use your CAS to do the computation here.
      </p>
      </statement>
      <answer>
      <p>
      <me>
      12\cdot \begin{bmatrix}
      14\\32\\21\end{bmatrix} + 9\cdot \begin{bmatrix}
      9\\7\\8\end{bmatrix} + 15\cdot \begin{bmatrix}
      34\\12\\5\end{bmatrix} + 7\cdot \begin{bmatrix}
      41\\52\\23\end{bmatrix}=
      \begin{bmatrix}
      1046\\991\\560
      \end{bmatrix}
      </me>
      This means we received $1046 from Company 1, $991 from Company 2, and $560 from Company 3.
      </p>
      </answer>
      </task>

      <task>
        <statement>
          <p>
            Since you allowed your CAS to do the computation for part (b), let's think about how it is 
            doing the arithmetic.  Using what we have defined for combining scalar multiplication and 
            vector addition in Equation 1.1.2, show the details of how the CAS was computing the resulting 
            vector that you obtained in part (b).
          </p>
        </statement>
        <answer>
          <p>
          <me>
          \begin{bmatrix}
          12\cdot14 \\12\cdot32 \\12\cdot21 \end{bmatrix} + \begin{bmatrix}
          9\cdot9 \\9\cdot7 \\9\cdot8 \end{bmatrix} + \begin{bmatrix}
          15\cdot34 \\15\cdot12 \\15\cdot5 \end{bmatrix} + \begin{bmatrix}
          7\cdot41 \\7\cdot52 \\7\cdot23 \end{bmatrix} = 
          </me>
          <p>
          <me>
          \begin{bmatrix}
          12\cdot14 + 9\cdot9 + 15\cdot34 + 7\cdot41 \\
          12\cdot32 + 9\cdot7 + 15\cdot12 + 7\cdot52 \\
          12\cdot21 + 9\cdot8 + 15\cdot5 + 7\cdot23
          \end{bmatrix} = 
          \begin{bmatrix}
          1046\\991\\560
          \end{bmatrix}
          </me> 
          </p>
          </p>
        </answer>
      </task>

      <task>
        <statement>
          <p>
          In general, we can think of the selling price for each of the four <term>Products</term> as scalars 
          <m> p_1, p_2, p_3, p_4 </m>.  Give a general expression in terms of <m> p_1, p_2, p_3, p_4 </m> 
          for the revenue generated by the purchases for the three companies expressing them as a 
          linear combination of three-entry revenue vectors (one entry for each company) resulting in the 
          revenue vector, <m>\begin{bmatrix} r_1\\r_2\\r_3\end{bmatrix}</m>.
          </p>
        </statement>
        <answer>
          <p>
            <me>
            p_1 \begin{bmatrix}
            14\\32\\21\end{bmatrix} + p_2 \begin{bmatrix}
            9\\7\\8\end{bmatrix} + p_3 \begin{bmatrix}
            34\\12\\5\end{bmatrix} + p_4 \begin{bmatrix}
            41\\52\\23\end{bmatrix} = \begin{bmatrix}
            r_1\\r_2\\r_3\end{bmatrix}
            </me>
          </p>
        </answer>
      </task>
    </activity>
  </p>
  
  <p>
Notice that where the product and sum are combined in part (c) we have the scalar values (or prices) of each 
<term>Product</term> ($12, $9, $15, and $7) being multipled by all entries in their respective vectors where the number 
of orders of each <term>Product</term> is placed in the vector in order by the company.  When these vectors are then added, 
we get the total revenue for each company organized as an ordered triple (since there are three companies).
  </p>
  
  <p>
   Here we are purposefully using an example where the number of entries in each set of values of interest 
   (prices and revenue) are different to highlight that although we can have the same number of entries in 
   each set be the same, it is not necessary.  Eventually we will express the prices as a vector consisting 
   of four entries and the revenue as a vector consisting of three entries where we can think of the process 
   of going from prices to revenue as a <em>transformation</em> between worlds so to speak.  In this case we 
   will have four entries in one set of vectors/world (prices of different Products) meaning that these vectors 
   exist in <m>\mathbb{R}^4</m> such as 
   <m>
   \begin{bmatrix}
   p_1\\p_2\\p_3\\p_4
   \end{bmatrix}
   </m> 
   and three entries in the other set of vectors/world (revenue from each of the three companies) existing in 
   <m>
   \mathbb{R}^3
   </m> 
   like 
   <m>\begin{bmatrix}
   r_1\\r_2\\r_3\end{bmatrix}
   </m>.
  </p>

  <p>
    In the previous activity, you may have noticed behaviors of the arithmetic when working with the vectors 
    and scalars that are familiar.  From your basic experiences in elementary school, you will recall some 
    properties for operating on numbers that seem to also be happening in your work with vectors.  Let's 
    explore these briefly by using the properties of vector addition and scalar multiplication we have 
    just defined.
  </p>
  
  <p>
  <activity>
      <title >Structure of Vectors</title >
      <introduction>
      <p>
        Consider the vectors 
        <m>\mathbf{u}=
            \begin{bmatrix}
            -1\\2\\5
            \end{bmatrix}</m>, 
        <m>\mathbf{v}=
            \begin{bmatrix}
            2\\3\\0
            \end{bmatrix}</m>, and
        <m>\mathbf{w}=
            \begin{bmatrix}
            -2\\-1\\4
            \end{bmatrix}</m>.
        Define each of these vectors in your computer algebra system (CAS).
      </p>
      </introduction>

      <task>
      <statement>
      <p>
        Based on what we know about how we have defined vector addition and the fact that all of these vectors 
        are in <m>\mathbb{R}^3</m>, when we add any two of them we will get another vector in <m>\mathbb{R}^3</m>.
        However, what other properties hold?  Using your CAS, compute <m>\mathbf{u}+\mathbf{v}</m> and then 
        compute <m>\mathbf{v}+\mathbf{u}</m>.  Describe what you notice?  Have you seen this behavior before 
        with real numbers?  What is this property called?
      </p>
      </statement>
      </task>

      <task>
      <statement>
      <p>
        Using your CAS, compute <m>\left(\mathbf{u}+\mathbf{v}\right)+\mathbf{w}</m>, first by computing 
        <m>\mathbf{u}+\mathbf{v}</m> and then adding <m>\mathbf{w}</m> to your result.  Now
        compute <m>\mathbf{u}+\left(\mathbf{v}+\mathbf{w}\right)</m>, first by computing 
        <m>\mathbf{v}+\mathbf{w}</m> and then adding your result to <m>\mathbf{u}</m>. Describe what you 
        notice?  Have you seen this behavior before with real numbers?  What is this property called?
      </p>
      </statement>
      </task>

      <task>
        <statement>
          <p>
            Using each of the vectors, <m>\mathbf{u}</m>, <m>\mathbf{v}</m>, and <m>\mathbf{w}</m>, add the 
            vector <m>\begin{bmatrix} 0\\0\\0\end{bmatrix}</m> to each.  Describe what you notice.  Have you 
            seen this behavior before with real numbers?  What is this property called?
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
          Using each of the vectors, <m>\mathbf{u}</m>, <m>\mathbf{v}</m>, and <m>\mathbf{w}</m>, negate 
          each entry of <m>\mathbf{u}</m> and add the resulting vector to <m>\mathbf{u}</m>.  Describe what 
          you notice.  Repeat this process with <m>\mathbf{v}</m> and <m>\mathbf{w}</m>.  Do you 
          get similar results?  Have you seen this behavior before with real numbers?  What is this property 
          called?
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
          Using your CAS, compute <m>2\cdot \left(\mathbf{u}+\mathbf{v}\right)</m>, first by computing 
          <m>\mathbf{u}+\mathbf{v}</m> and then multiplying 2 times your result.  Now compute 
          <m>2\cdot \mathbf{u}+2\cdot \mathbf{v}</m>, first by computing 2 times each vector and then 
          adding your results together. Describe what you notice?  Have you seen this behavior before with 
          real numbers?  What is this property called?
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
          Given that <m>2+3=5</m>, compute <m>5\cdot \left(\mathbf{u}+\mathbf{v}\right)</m> and 
          <m>2\cdot \mathbf{u} + 3\cdot \mathbf{v}</m>.  Describe what you notice?  Have you seen this 
          behavior before with real numbers?  What is this property called?
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
          Using your CAS, compute <m>2 \left(3\mathbf{u}\right)</m>, first by computing 
          <m>3\mathbf{u}</m> and then multiplying 2 times your result.  Now compute 
          <m>\left(2\cdot3\right) \mathbf{u}</m>, first by computing 2 times 3 and then 
          multiplying your result by <m>\mathbf{u}</m>. Describe what you notice?  Have you seen this 
          behavior before with real numbers?  What is this property called?
          </p>
        </statement>
      </task>
    </activity>
  </p>

  <p>
    Since we have seen these properties before from our work with real numbers, we can use them with 
    vectors and scalars so that we can manipulate these combinations of operations.  To this end, we can define 
    a "world" where objects like vectors and scalars behave in a way that we expect and can use.
  </p>
  <p>
    <definition xml:id="def-vector-space">
    <title>Vector Space</title>
      <statement>
        <p>
          A <term>vector space</term> is a nonempty set <m>V</m> of objects, called
          <em>vectors</em>, on which are defined two operations, called <em>addition</em> and 
          <em>scalar multiplication</em> (for real numbers), that satisfy the following axioms.  
          For any  <m>\mathbf{u}, \mathbf{v}, \mathbf{w} \in V</m> and <m>c, d \in \mathbb{R}</m>:
          <ol>
            <li>
              <p>
                <m>\mathbf{u}+\mathbf{v} \in V</m>
              </p>
            </li>
            <li>
              <p>
                <m>\mathbf{u}+\mathbf{v}=\mathbf{v}+\mathbf{u}</m>
              </p>
            </li>
            <li>
              <p>
                <m>\left(\mathbf{u}+\mathbf{v}\right)+\mathbf{w}=\mathbf{u}+\left(\mathbf{v}+\mathbf{w}\right)</m>
              </p>
            </li>
            <li>
              <p>
                There exists a <em>zero vector</em>, denoted <m>\mathbf{0} \in V</m>, such that 
                <m>\mathbf{u}+\mathbf{0}=\mathbf{u}, \forall \mathbf{u} \in V</m>.
              </p>
            </li>
            <li>
              <p>
                For each <m>\mathbf{u} \in V</m>, there exists a vector denoted <m>-\mathbf{u} \in V</m> 
                such that <m>\mathbf{u}+\left(-\mathbf{u}\right)=\mathbf{0}</m>.
              </p>
            </li>
            <li>
              <p>
                The scalar multiple of <m>\mathbf{u}</m> by <m>c</m>, denoted <m>c\mathbf{u} \in V</m>.
              </p>
            </li>
            <li>
              <p>
                <m>c\left(\mathbf{u}+\mathbf{v}\right)=c\mathbf{u}+c\mathbf{v}</m>
              </p>
            </li>
            <li>
              <p>
                <m>\left(c+d\right)\mathbf{u}=c\mathbf{u}+d\mathbf{u}</m>
              </p>
            </li>
            <li>
              <p>
                <m>c\left(d\mathbf{u}\right)=\left(cd\right)\mathbf{u}</m>
              </p>
            </li>
            <li>
              <p>
                <m>1\mathbf{u}=\mathbf{u}</m>
              </p>
            </li>
          </ol>
        </p>
      </statement>
    </definition>
  </p>
  </subsubsection>

<subsubsection xml:id="sec-Transform-Data-Matrix-Mult">
  <title>Transforming Data and Matrix Multiplication</title>
  <p>
    As we have seen, we can use vectors to represent any entity that might have multiple components.  This allows 
    us to manipulate values of common components by adding or multiplying them while keeping the 
    components separated in the process.  This use of linear combinations of vectors is useful, but the 
    real desire of the previous scenario is to examine how manipulating one set of values (say, prices of 
    products) affects another set of values (revenue from each company).  Just as we explored functional 
    relationships in algebra and calculus, we also might want to explore functional relationships with 
    objects that have not just one value as an input and one corresponding value as an output, but rather 
    inputs that have many component values and a corresponding output that also has many component values.
  </p>
  <p>
    Recall that one of our first experiences with functions dealt with simple linear relationships.  For 
    example, Hooke's Law states that there is a simple linear relationship between force on a stretched 
    or compressed spring and the distance of the associated stretch or compression, <m>F=kx</m>, where <m>k</m> 
    is a constant of proportionality.  If we use <em>function notation</em> to express that force, 
    <m>F</m>, is a function of stretch, <m>x</m>, we indicate the independent variable by placing it in 
    parentheses getting, <m>F\left(x\right)=kx</m>.
  </p>
  <p>
    In this situation, we obtain the force as an output by multiplying the stretch, <m>x</m>, by a numerical 
    value, <m>k</m>.  What if in our scenario for the relationship between pricing of products and the 
    revenue generated from each of our three companies, we could have a simple multiplication by something 
    that acted like <m>k</m> in our Hooke's Law relationship?  In the <m>F\left(x\right)=kx</m> case, there 
    is a single value, <m>k</m>, that affects the output, <m>F</m>, for a given input, <m>x</m>.  However, 
    in the situation with price vs revenue, there are many values impacting the output of revenue for an 
    input vector of prices (namely, all of the different order values provided by the companies placing 
    orders).  So, our <em>k</em>-equivalent must take into account all of the values of the orders placed 
    by the companies.  Here we can think of our single multiplier (like that of <m>k</m>) as being 
    comprised of an array of order values for the products like we had for the linear combination of the vectors 
     <me>
\left\{ \begin{bmatrix}
        14\\32\\21
        \end{bmatrix}
        ,\begin{bmatrix}
        9\\7\\8
        \end{bmatrix}
        ,\begin{bmatrix}
        34\\12\\5
        \end{bmatrix}
        ,\begin{bmatrix}
        41\\52\\23
        \end{bmatrix}
\right\}
    </me>
    except now we express this set of vectors as a single matrix where each column is a vector (called a 
    <em>column vector</em>).  This gives an entity (matrix) 
    <me>
       \begin{bmatrix}
14\amp 9\amp 34\amp 41\\
32\amp 7\amp 12\amp 52\\
21\amp 8\amp 5\amp 23
\end{bmatrix}
    </me>
    that serves the role that <m>k</m> did in <m>F=kx</m>.

  </p>
  <p>
    What this does for us is it allows us to think of the scalars (prices) we used in the linear combination, 
    <me>
      p_1 \begin{bmatrix}
      14\\32\\21\end{bmatrix} + p_2 \begin{bmatrix}
      9\\7\\8\end{bmatrix} + p_3 \begin{bmatrix}
      34\\12\\5\end{bmatrix} + p_4 \begin{bmatrix}
      41\\52\\23\end{bmatrix} = \begin{bmatrix}
      r_1\\r_2\\r_3\end{bmatrix}
     </me>
     as an input vector, 
     <m>
   \begin{bmatrix}
   p_1\\p_2\\p_3\\p_4
   \end{bmatrix}
    </m>,
    so that we get a relationship that is structurally similar to <m>F=kx</m>:
    <me>\begin{bmatrix}
   r_1\\r_2\\r_3\end{bmatrix} =
    \begin{bmatrix}
14\amp 9\amp 34\amp 41\\
32\amp 7\amp 12\amp 52\\
21\amp 8\amp 5\amp 23
\end{bmatrix}

\begin{bmatrix}
   p_1\\p_2\\p_3\\p_4
   \end{bmatrix}
   </me>
   where <m>\begin{bmatrix}
   r_1\\r_2\\r_3\end{bmatrix} </m> acts like <m>F</m>, <m>\begin{bmatrix}
   p_1\\p_2\\p_3\\p_4
   \end{bmatrix}</m> acts like <m>x</m>, and <m>\begin{bmatrix}
14\amp 9\amp 34\amp 41\\
32\amp 7\amp 12\amp 52\\
21\amp 8\amp 5\amp 23
\end{bmatrix}</m> acts like <m>k</m>.
  </p>
  <p>
    The use of a matrix as a single entity that we can use to multiply by a vector brings an interesting 
    question.  What does it mean to multiply by a matrix?  If we look at what we want to do from our 
    functional perspective in the case above, we would like to have the outputs represent the revenue 
    in the way we ultimately added them up in the linear combination of the vectors with the prices 
    viewed as scalars for the column vectors in the matrix.  This means that we will need to define the 
    multiplication of a matrix and a vector in such a way that we get:
    <me>
    \begin{bmatrix}
14\amp 9\amp 34\amp 41\\
32\amp 7\amp 12\amp 52\\
21\amp 8\amp 5\amp 23
\end{bmatrix}

\begin{bmatrix}
   p_1\\p_2\\p_3\\p_4
   \end{bmatrix} = 

   \begin{bmatrix}
      p_1\cdot14 + p_2\cdot9 + p_3\cdot34 + p_4\cdot41 \\
      p_1\cdot32 + p_2\cdot7 + p_3\cdot12 + p_4\cdot52 \\
      p_1\cdot21 + p_2\cdot8 + p_3\cdot5 + p_4\cdot23
      \end{bmatrix} =
    </me>
    <me>
      p_1 \begin{bmatrix}
      14\\32\\21\end{bmatrix} + p_2 \begin{bmatrix}
      9\\7\\8\end{bmatrix} + p_3 \begin{bmatrix}
      34\\12\\5\end{bmatrix} + p_4 \begin{bmatrix}
      41\\52\\23\end{bmatrix}
     </me>
    Now this may seem complicated, but one way to look at the process is that we proceed across a row in 
    the matrix while moving down the vector component by component adding the products of the row entries 
    of the matrix and the corresponding component entries of the vector.  For example, for the top entry 
    in the resulting revenue vector, we obtained it by moving across the first row with values 14, 9, 34, 
    and 41, while multiplying each by their respective position price value <m>p_1</m>, <m>p_2</m>, <m>p_3</m>, 
    and <m>p_4</m> and then adding these four products together.  This gives <m>
    p_1\cdot14 + p_2\cdot9 + p_3\cdot34 + p_4\cdot41</m>.  Now we proceed similarly for each row moving across 
    the row and down the vector creating product combinations and adding them together as we go.  The row 
    of the matrix we use for the computation becomes the row position in the resulting vector we are 
    creating (in this case, revenue).
    <me>
    \begin{bmatrix}
14\amp 9\amp 34\amp 41\\
32\amp 7\amp 12\amp 52\\
21\amp 8\amp 5\amp 23
\end{bmatrix}

\begin{bmatrix}
   p_1\\p_2\\p_3\\p_4
   \end{bmatrix} = 

   \begin{bmatrix}
      p_1\cdot14 + p_2\cdot9 + p_3\cdot34 + p_4\cdot41 \\
      p_1\cdot32 + p_2\cdot7 + p_3\cdot12 + p_4\cdot52 \\
      p_1\cdot21 + p_2\cdot8 + p_3\cdot5 + p_4\cdot23
      \end{bmatrix} = 
      \begin{bmatrix}
      r_1\\r_2\\r_3\end{bmatrix}
    </me>
    You will likely notice that the result of the way we have chosen to define the multiplication of a 
    matrix and a vector only makes sense if the number of columns of the matrix matches the number of 
    entries (rows of components) of the vector.
  </p>
</subsubsection>

<subsubsection xml:id="sec-Transformations-Vectors">
  <title>Transformations of Vectors</title>
  <p>
    Now that we have defined what it means to multiply a matrix and a vector, we can go back to the concept 
    that motivated it, namely, the desire to move between an input vector and an output vector.  In a way, 
    we are looking to <em>transform</em> one type of vector into another type of vector.  When we think of 
    our example of Hooke's Law as <em>transforming</em> stretch or compression into force, we note that this 
    happens in our daily lives and we are not often even aware it is there.
    </p>

    <p>
      Consider a trip to the grocery 
      store.  In the produce aisle, we take zucchini and place them on a scale.  In turn, the scale returns a 
      weight (force) in pounds (if you are in the USA) or mass in kilograms (practically anywhere else in the 
      world).  Inside the scale, there is a spring that is being compressed or stretched.  This value is then 
      <em>transformed</em> into a value of weight or mass using Hooke's Law.  In fact, it is more likely the 
      case that you are more familiar with a transformation in form of cost instead of weight or mass 
      as most digital scales today allow us to scan the scale's output barcode registering a cost in our 
      "shop and scan" app.  Below is a video illustrating this process.  
  </p>
  <p>
    <figure xml:id="linear-transformation-video">
      <video youtube="mzqYk0K7FMA"/>
      <caption>The Produce Aisle: Concept of Linear Transformation</caption>
    </figure>
  </p>
  <p>
    So what are the characteristics of this type of transformation?  Consider the case from the video where 
    we saw that the doubling the force (or mass) corresponded in the doubling of the stretch.  Similarly, 
    tripling the force would triple the stretch.  In general, this means that any multiple of stretch will 
    correspond to the same multiple of force (or mass or cost) depending on the output we desire for the 
    transformation.  We can see this from the basic algebra from Hooke's Law.
    <me>
      F\left(2x\right)=k\left(2x\right)=2\left(kx\right)=2F\left(x\right)
    </me>
    What this says is that <em>scalar multiplication is preserved</em>.
  </p>
  <p>
    Now this is all well and good if we are looking at replicating the same stretch multiple times (e.g. all of 
    our zucchini are the exact same weight), but what about the case where we have multiple numbers of 
    zucchini of varying weight (corresponding to varying stretches)?  We also want to have it be the case that 
    if we place two different "stretch" zucchinis on the scale that the resulting weight will simply be added 
    together as well so that their corresponding costs will also be added together (since we are paying based 
    on the cost/unit weight).  In this case, suppose we have two possibly different stretches <m>x</m>, and 
    <m>y</m>.  Here we get 
    <me>
      F\left(x+y\right)=k\left(x+y\right)=kx+ky=F\left(x\right)+F\left(y\right)
    </me>
    What this says is that <em>vector addition is preserved</em>.  In this case, we can think of the inputs, 
    <m>x</m> and <m>y</m>, as vectors with only one component.  In fact, if you have ever taken a physics class, 
    you will recall that both force and stretch in Hook'e Law were considered vectors since along a single 
    line we associate a positive and negative direction for these values to indicate direction of the force 
    or stretch.  We often represent this relationship as a vector relationship, 
    <m>\mathbf{F}=k\mathbf{x}</m> or <m>\overset{\rightharpoonup}{F}=k\overset{\rightharpoonup}{x}</m>.
  </p>
  <p>
    Recall from your Algebra 1 days, a function like <m>F=kx</m> is the most basic of linear functions.  
    Therefore, it should come as no surprise that these two aspects of behavior (preservation of scalar 
    multiplication and vector addition) by this type of function are the defining properties of what we call 
    <em>linear transformations</em>.
  </p>
  <p>
    <activity>
      <introduction>
      <p>
        In the case of the force and spring stretch, we had a spring constant, <m>k</m>, as our <em>constant of 
        proportionality</em> where it was a single value that worked for a specific spring.  As we have seen, 
        we may have relationships where this "constant" is actually dependent on many different values instead 
        of a single one (i.e. a matrix of values).  Can we still have these two operations (scalar 
        multiplication and vector addition) work when the thing we are multiplying the vectors by is a matrix?  
        Suppose we have a matrix transformation given by <m>T\left(\mathbf{x}\right)=
        \begin{bmatrix}
        -1 \amp 3 \amp 1\\
        2 \amp 5 \amp 2\\
        1 \amp 0 \amp -1
        \end{bmatrix}\mathbf{x}</m>.  
        Define this transformation in your CAS and then define 
        <m>\mathbf{v}=\begin{bmatrix} -2\\1\\0\end{bmatrix}</m> and 
        <m>\mathbf{w}=\begin{bmatrix} 3\\2\\-2\end{bmatrix}</m>.
      </p>
      <p>
        <figure xml:id="defining-transformation-nspire">
          <caption>Defining Transformation on TI-Nspire CX II CAS</caption>
          <image source="images/lineartransformation-act-1-1-3.png" width="60%">
          <shortdescription>Defining on TI-Nspire CX II CAS</shortdescription>
        </image>
        </figure>
      </p>
      </introduction>

      <task>
      <statement>
      <p>
        Compute <m>T\left(\mathbf{v}\right)</m> and <m>T\left(\mathbf{w}\right)</m> and add them.
      </p>
      </statement>
      </task>

      <task>
      <statement>
      <p>
        Compute <m>\mathbf{v}+\mathbf{w}</m> and <m>T\left(\mathbf{v}+\mathbf{w}\right)</m>.  Describe 
        your observations relative to your responses from part(a).
      </p>
      </statement>
      </task>

      <task>
        <statement>
          <p>
            Compute <m>T\left(4\mathbf{v}\right)</m> and <m>4T\left(\mathbf{v}\right)</m>.  Describe your 
            observations.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
          To see if your observations will hold in general for this particular matrix, create two vectors 
          on your CAS , <m>\mathbf{x}=\begin{bmatrix} x_1\\x_2\\x_3\end{bmatrix}</m> and 
          <m>\mathbf{y}=\begin{bmatrix} y_1\\y_2\\y_3\end{bmatrix}</m>.  Using your CAS, find expressions 
          for <m>T\left(\mathbf{x}+\mathbf{y}\right)</m> and 
          <m>T\left(\mathbf{x}\right)+T\left(\mathbf{y}\right)</m>.  Does your earlier observation hold for any 
          two vectors in <m>\mathbb{R}^3</m>?  Explain.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
          Using, <m>c</m>, to represent any real number, find expressions for 
          <m>T\left(c\cdot \mathbf{x}\right)</m> and <m>c\cdot T\left(\mathbf{x}\right)</m>.  Does your 
          observation from part (c) hold for all vectors in <m>\mathbb{R}^3</m>?  Explain.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
            Given how we defined matrix-vector multiplication out of linear combiinations, come up with an 
            argument for why all such matrix transformations <em>must</em> be 
            <m>\mathbf{linear}</m> <m>\mathbf{transformations}</m> preserving both scalar multiplication and vector addition.
          </p>
        </statement>
      </task>
    </activity>
  </p>
  <p>
  <definition xml:id="def-linear-mapping">
    <title>Linear Transformation</title>
    
    <statement>
      <p>
        Suppose <m>T</m> is a mapping between <m>\mathbb{R}^n</m> and <m>\mathbb{R}^m</m>, 
        <m>T: \mathbb{R}^n\rightarrow \mathbb{R}^m</m> (<m>n</m> and <m>m</m> need not be distinct) 
        such that both scalar multiplication and vector addition are preserved.
        <me>
          T\left(\alpha \mathbf{v}\right)=\alpha T\left(\mathbf{v}\right)
        </me>
        
        <me>
          T\left(\mathbf{v}+\mathbf{w}\right)=T\left(\mathbf{v}\right)+T\left(\mathbf{w}\right)
        </me>
        where <m>\mathbf{v}, \mathbf{w} \in \mathbb{R}^n</m>, and <m>\alpha</m> is a scalar.  
        Then the mapping <m>T</m> is called <term>linear</term> or a <term>linear transformation</term>.
      </p>
    </statement>
  </definition>
  </p>
    <p>
    Just as the relationship of Hooke's Law can be thought of as transforming <em>stretch</em> into <em>force</em>, 
    in our scenario between pricing structures and the revenue generated, we are similarly looking to transform a 
    pricing scheme into the resulting revenue for our three companies.  We can even use function notation to 
    represent this relationship.  If we let the vector <m>\mathbf{p}=\begin{bmatrix}
   p_1\\p_2\\p_3\\p_4 \end{bmatrix}</m>, we can think of the product of the matrix of orders by the companies 
   and the vector <m>\mathbf{p}</m> as a revenue transformation (or function), <m>R</m>, given by  
   <me>
    R\left(\mathbf{p}\right)=
    \begin{bmatrix}
    14\amp 9\amp 34\amp 41\\
    32\amp 7\amp 12\amp 52\\
    21\amp 8\amp 5\amp 23
    \end{bmatrix}
    \mathbf{p} = 
    \begin{bmatrix}
    14\amp 9\amp 34\amp 41\\
    32\amp 7\amp 12\amp 52\\
    21\amp 8\amp 5\amp 23
    \end{bmatrix}
    \begin{bmatrix}
    p_1\\p_2\\p_3\\p_4
    \end{bmatrix}
   </me>
   This is effectively a mapping between vectors in <m>\mathbb{R}^4</m> and vectors in <m>\mathbb{R}^3</m>.  
   We can represent this mapping as <m>R:\mathbb{R}^4 \rightarrow \mathbb{R}^3</m>.

  </p>
  <p>
  <activity>
    <title>Price to Revenue: Linear Transformation?</title>
    <introduction>
      <p>
        In the previous activity, we illustrated how we can show that a matrix transformation between 
        the same spaces (<m>\mathbb{R}^3</m> to <m>\mathbb{R}^3</m>) is, in fact, a linear transformation.  
        In this activity, let's take a similar approach to show we can also make the same claim for mappings 
        between different spaces (<m>\mathbb{R}^4</m> to <m>\mathbb{R}^3</m>).  Here we will use our earlier 
        example of transforming price scenarios into revenues for our three companies.
      </p>
    </introduction>
    
    <task>
      <statement>
        <p>
          Consider the transformation 
          <m>R=T\left(\mathbf{p}\right)=
              \begin{bmatrix}
              14\amp 9\amp 34\amp 41\\
              32\amp 7\amp 12\amp 52\\
              21\amp 8\amp 5\amp 23
              \end{bmatrix}
              \mathbf{p}</m>, 
            where <m>\mathbf{p}=\begin{bmatrix} p_1\\p_2\\p_3\\p_4\end{bmatrix}</m>.  Find expressions for 
            <m>T\left(c\cdot \mathbf{p}\right)</m> and <m>c\cdot T\left(\mathbf{p}\right)</m>.  
            Is scalar multiplication preserved for all vectors in <m>\mathbb{R}^4</m>?  Explain.
        </p>
      </statement>
    </task>

    <task>
      <statement>
        <p>
          To see if preservation of vector addition holds in general for this particular matrix, create 
          two vectors on your CAS , <m>\mathbf{p}=\begin{bmatrix} p_1\\p_2\\p_3\\p_4\end{bmatrix}</m> and 
          <m>\mathbf{q}=\begin{bmatrix} q_1\\q_2\\q_3\\q_4\end{bmatrix}</m>.  Using your CAS, 
          find expressions for <m>T\left(\mathbf{p}+\mathbf{q}\right)</m> and 
          <m>T\left(\mathbf{p}\right)+T\left(\mathbf{q}\right)</m>.  Is vector addition preserved for any  
          two vectors in <m>\mathbb{R}^4</m>?  Explain.
          </p>
      </statement>
    </task>
  </activity>
  </p>
  <p>
    <lemma xml:id="lem-zero-vector-map">
      <statement>
        <p>
          If <m>T</m> is a linear transformation, then it must map the zero vector from the domain to the 
          zero vector in the range.  In other words, <m>T\left(\mathbf{0}_D\right)=\mathbf{0}_R</m>.
        </p>
      </statement>
      <proof>
        <p>
          Suppose <m>T:\mathbb{R}^n \rightarrow \mathbb{R}^m</m> is a linear transformation and 
          <m>\mathbf{v} \in \mathbb{R}^n</m>.  Well since <m>-\mathbf{v} \in \mathbb{R}^n</m>, we know that 
          <m>T\left(\mathbf{0}_n\right)=T\left(\mathbf{v}+\mathbf{-v}\right)</m> where <m>\mathbf{0}_n</m> here 
          is in <m>\mathbb{R}^n</m>.  Since vector addition is preserved, we get that this is equal to 
          <m>T\left(\mathbf{v}\right)+T\left(\mathbf{-v}\right)</m>.  Again, as a linear transformation, 
          we know that scalar multiplication is also preserved and so 
          <m>T\left(\mathbf{-v}\right)=-T\left(\mathbf{v}\right)</m> and thus 
          <m>T\left(\mathbf{v}\right)+T\left(\mathbf{-v}\right)=T\left(\mathbf{v}\right)+ 
          -T\left(\mathbf{v}\right)=\mathbf{0}_m</m> where <m>\mathbf{0}_m</m> here is in <m>\mathbb{R}^m</m>.
        </p>
      </proof>
    </lemma>
  </p>
  <p>
    We began this section looking at how we can represent practical data and relationships using matrices 
    and vectors along with operations allowing us to transform one type of vector into another.  In the next few 
    sections, we will extend this view to consider geometric representations that have far reaching 
    applications into areas such as digital file compression and image detection.  Eveytime you access your 
    phone using facial recognition, you are using linear algebra.  Vectors and matrices play a key role 
    in your everyday life and you may not even be aware of it!
  </p>
</subsubsection>

</subsection>

<subsection xml:id="subsec-solving-systems">
  <title>Solving Systems of Equations</title>

<introduction>
  <p>
    In this subsection we will explore processes surrounding solving systems of linear equations.  In the last 
    section, we ended by experimenting with various scalars to determine if a set of vectors were linearly 
    independent.  Mostly we used trial and error or tried to reduce the linear combinations by chosing 
    a value for one of the scalars and then working backwards to find the remaining scalars.  This was a 
    time-consuming process and can often be challenging if there is a unique solution.  In this section, we 
    will try a more systematic approach that will help us find the desired scalars more efficiently.  
  </p>
</introduction>
  
  <subsubsection xml:id="finding-scalars">
    <title>Finding Scalars: Gaussian Elimination</title>
    
  <p>
    As we ended section 2.1, we wanted to establish whether or not a set of vectors was linealry independent.  
    To do this, we needed to determine whether or not we could find a set of scalar values that would give 
    us a linear combination for other vectors in the set.  In addition, we sought to determine the if a 
    vector was in the <term>Span</term> of a set of vectors.  For both of these questions, we ultimately 
    want to solve for specific scalars that would meet our desired requirements.
  </p>
  <p>
    While this process of finding scalars may seem new, it is actually not a new idea.  Recall that in high 
    school we solved systems of equations using a variety of techniques including substitution, elimination, and 
    graphing.  As the number of variables and equations increased, the techniques of substitution and 
    graphing became very challenging.  The process of elimination was generally easier as the number of 
    variables increased and so this process is the one we will refine here.
  </p>
  <p>
    You may recall that there were certain operations we could perform on equations so that their solution 
    sets did not change.  These included multiplying an equation by a nonzero constant, adding equals to equals, 
    and rearranging the equations.  For example, since, say, <m>5=5</m>, we can also say that 
    <m>2\cdot5=2\cdot5</m>.  Similarly for an equation like <m>x+2y=5</m> (for which a solution is clearly 
    <m>x=1</m> and <m>y=2</m>), then if we multiply both sides by, say 3, we get 
    <m>3\left(x+2y=5\right) \Rightarrow 3x+6y=3\cdot5\Rightarrow 3x+6y=15</m>.  Just as <m>x=1</m> and <m>y=2</m> 
    is a solution to the original equation, due to the fact that multiplying both sides of an equation by the same 
    value gives a new equation that is also true, <m>x=1</m> and <m>y=2</m> is also a solution to 
    <m>3x+6y=15</m> (i.e. <m>3\cdot1+6\cdot2=3+12=15</m>).
  </p>
  <p>
    In a similar fashion, if we start with <m>x+2y=5</m> and add the same amount to both sides, we get 
    <m>x+2y+7=5+7 \Rightarrow x+2y+7=12</m>.  If we plug in <m>x=1</m> and <m>y=2</m> we get 
    <m>1+2\cdot2+7=1+4+7=12</m>.  In both cases, if we start with an equation with a certain solution, adding 
    the same constant to both sides or multiplying both sides by the same constant will give a new 
    equation for which the solution to the original equation will be a solution to the new equation.
  </p>
  <p>
    What if we want to add expressions to both sides of an equation?  Consider another equation, 
    <m>4x+y=6</m>, that also has a common solution, <m>x=1</m> and <m>y=2</m>.  If we add this equation to 
    or earlier equation, <m>x+2y=5</m>, we get 
    <me>
      \begin{array} 3 x+2y=5\\4x+y=6\\\overline{5x+3y=11}\end{array}
    </me>
    where <m>x=1</m> and <m>y=2</m> is still a solution to the result, <m>5x+3y=11</m> (see 
    <xref ref="three-lines"/>).  What this tells us is that if we seek solutions to a system of equations, 
    we can add any of the equations in the system to each other and get a new equation that also shares 
    the same solution(s) as the previous equations.
  </p>
  <p>
    <figure xml:id="three-lines">
      <caption>Three Lines</caption>
      <image source="images/three-lines.png" width="60%">
        <shortdescription>(for accessibility)</shortdescription>
      </image>
    </figure>
  </p>
  <p>
    So now suppose we did not know that the solution to our earlier set of equations, <m>x+2y=5</m> and 
    <m>4x+y=6</m>, was <m>x=1</m> and <m>y=2</m>.  How do these manipulations that yield new equations with 
    the same solution help us?  As you may recall from your earlier mathematics experiences, we can take the 
    approach of trying to "eliminate" a variable from the system so that we can more easily solve for one of 
    the variables.  In this case, consider what would happen if we multipled the top equation by -4.  This 
    would give us a new equation, <m>-4x-8y=-20</m>, and we can use it in place of the original one.  Why multiply 
    it by -4?  As we saw, if two equations share the same solution(s), we can add them and the resulting 
    equation will also have the same solution(s).  The -4 was selected since it will give a coefficient of 
    <m>x</m> that is the opposite of the coefficient of <m>x</m> in the second equation so that when added 
    they will cancel each other to leave us only the variable <m>y</m>.
  </p>
  <p>
    <me>
      \begin{array} 2 -4(x+2y=5)\\\quad 4x+\; y=6\end{array}
      \Rightarrow
      \begin{array} 3 \quad -4x-8y=-20\\ \quad\;\; 4x+\;\, y=\quad\; 6\\ \quad \overline{\quad 0x-7y=-14}\end{array}
      \Rightarrow
      -7y=-14 \Rightarrow y=2
    </me>
    Now we can simply plug <m>y=2</m> into either of our original equations to get a value for <m>x</m>.  
    Let's use the first equation as it is easier to solve for <m>x</m>.  This gives <m>x+2\cdot2=5</m> which 
    yields <m>x+4=5 \Rightarrow x=1</m>.
  </p>
  <p>
    <em>Now consider the following example where we use this process to find scalars for a linear 
      combination of vectors.
    </em>
  </p>
  <p>
    <example xml:id="find-scalars">
    <title>Finding Scalars</title>
    <p>
      Consider a more simplified version of our scenario from Chapter 1 involving prices, <m>p</m> and revenue 
      <m>r</m> for products we are selling to various companies.  In this case, we consider fewer companies 
      and products to make this example easier to disect.  Suppose we have the following data for the number 
      of items for two different products for two different companies.
    </p>
    <p>
      <table xml:id="product-orders-small">
      <title>Product Orders</title>
      <tabular halign="center">
      <row header="yes" bottom="minor">
        <cell>Clients</cell>
        <cell>Product 1</cell>
        <cell>Product 2</cell>
      </row>
      <row>
        <cell>Company 1</cell>
        <cell>2</cell>
        <cell>3</cell>
      </row>
      <row>
        <cell>Company 2</cell>
        <cell>1</cell>
        <cell>5</cell>
      </row>
  </tabular>
</table>
    </p>
    <p>
      In this case we are looking for scalars for prices, <m>p_1</m> and <m>p_2</m>, that provide desired revenues, 
    <m>r_1</m> and <m>r_2</m>.  This gives the following vector equation.
    </p>
    <p>
      <me>
            p_1 \begin{bmatrix}
            2\\1\end{bmatrix} + p_2 \begin{bmatrix}
            3\\5\end{bmatrix} = \begin{bmatrix}
            r_1\\r_2\end{bmatrix}
      </me>
    </p>
    <p>
      A question we might ask is what prices do we need to set so that we have revenue of $43 from 
      Company 1 and $46 from Company 2?  It may be that there are no such price combinations that will 
      yield what we want (i.e. does this combination exist?).  There may be a case where there are 
      infinitely many such price combinations (i.e. there is not uniqueness).  These two fundamental 
      questions of <term>existence</term> and <term>uniqueness</term> will be ones we revisit as we seek 
      solutions to equations.
    </p>
    <p>
      So now we ask if we can find solutions to the vector equation, 
      <m>p_1 \begin{bmatrix}
            2\\1\end{bmatrix} + p_2 \begin{bmatrix}
            3\\5\end{bmatrix} = \begin{bmatrix}
            43\\46\end{bmatrix}
      </m>?
    </p>
    <p>
      However, this is not such an unusual task.  Recall from high algebra we solved these equations before, 
      but they were simply written in a different form.  This vector equation could also be written as 
      <me>
        2p_1+3p_2=43
      </me>
      <me>
        p_1+5p_2=46
      </me>
    </p>
    <p>
      Now we can use the process of Gaussian elimination to reduce these equations to only one variable.  Suppose 
      we multiply the second equation by <m>-2</m> and add the resulting equations to obtain the following.
    </p>
    <p>
      <me>
        \begin{array} 2 \quad 2p_1+3p_2=43\\ -2(p_1+ 5p_2=46)\end{array}
        \Rightarrow
        \begin{array} 3 \quad 2p_1+3p_2=\quad 43\\ -2p_1-10p_2= -92\\
        \overline{\quad 0p_1- \; 7p_2=-49}\end{array}
        \Rightarrow
        -7p_2=-49 \Rightarrow p_2=7
      </me>
    </p>
    <p>
      Now we can use our value for <m>p_2=7</m> in one of our original equations (let's use the second one 
      since it is easier) to get <m>p_1+5\cdot7=46</m> which gives <m>p_1=46-35=11</m>.
    </p>
    <p>
      Checking this result we get 
      <m>11\cdot \begin{bmatrix}
        2\\1\end{bmatrix} + 7\cdot \begin{bmatrix}
        3\\5\end{bmatrix} = \begin{bmatrix}
        43\\46\end{bmatrix}
      </m>.
    </p>
    
    </example>
  </p>
  <p>
    <activity xml:id="solve-3by3-system">
      <introduction>
        <p>
          Consider the following system of equations.
        </p>
        <p>
          <me>
              \begin{array} 3
              x + 2y + z =-1 \\
              2x - y + 3z =6 \\
              -x + 4y - z =-5
              \end{array}
          </me>
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            Use the process of Gaussian elimination to reduce the system of 3 equations and 3 unknowns to 
            a system of 2 equations and 2 unknowns by scaling and/or adding pairs of these equations.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
            Now eliminate another of your two remaining variables from part (a) in similar manner 
            (scaling and/or adding pairs of these equations) to find a solution value for one of the three 
            variables. 
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
            Use your value from part (b) and one of your equations found in part (a) to solve for a second 
            unknown.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
            Use the two values you have found so far along with one of your original equations to solve for 
            the last unknown.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
            Use the GeoGebra applet in <xref ref="3d-system-graphical" /> to verify your solution to the system.  
            Feel free to rotate the planes so that the intersection point of all three is visible.
          </p>
          
          <p>
            <figure xml:id="3d-system-graphical">
              <caption>3D System of Equations</caption>
              <interactive xml:id="geogebra-3d-example" platform="geogebra" width="100%" reset-icon="yes">
                <slate xml:id="ggb-3d-example" surface="geogebra" material="ytewv5yw" />
              </interactive>
            </figure>
          </p>
          
        </statement>
      </task>
    </activity>
  </p>

  <p>
    Now that we have worked through a process to reduce a system of equations to fewer and fewer variables, 
    we can summarize the operations that changed the look of the equations without changing the solutions.  
    We essentially have three types of "moves" we can do that will create equivalent systems of equations that 
    maintain the same solutions as the original system.
  </p>

  <p>
    <description>
      <item>
        <term>Scaling</term>
        <details>
          <p>In this situation, we can multiply an entire equation by a constant and not change the solutions.  
            For example, <m>\frac{1}{2} \left(2x+4y=8\right) \Rightarrow x+2y=4</m> will have the same solutions 
            as the original, <m>2x+4y=8</m>.
          </p>
          <p>
            
          </p>
        </details>
      </item>
      <item>
        <term>Swapping</term>
        <details>
          <p>
            Here we are allowing the position of the listed equations within the system to be simply swapped.  
            This principle is kind of obvious since the two systems of equations
            <me>
              \begin{aligned}
              3x+2y=1 \\
              -x+5y=11
              \end{aligned}
              \quad \text{and} \quad
              \begin{aligned}
              -x+5y=11\\
              3x+2y=1
              \end{aligned}
            </me>
            clearly have the same solution!
            
          </p>
          <p>
            
          </p>
        </details>
      </item>
      <item>
        <term>Replacing</term>
        <details>
          <p>In this situation, we found that if we multiply one equation by a scalar (even if it is just 1)  
            and add it to another equation and use this result in place of the equation we added the 
            scalar multiple to, the solutions to the system remain the same.  For example, we can take a system 
            like
            <me>
              \begin{aligned}
              3x+2y=1 \\
              -x+5y=11
              \end{aligned}
            </me>
            and take, say 3, times the bottom equation and add it to the top equation replacing the top equation 
            with this result to get 
            <me>
              \begin{aligned}
              0x+17y=34 \\
              -x+5y=11
              \end{aligned}
            </me>
            and we will still have the same solution, <m>x=-1</m> and <m>y=2</m>, be the solution to both systems.
            
          </p>
          <p>
            
          </p>
        </details>
      </item>
      </description>
  </p>

  <p>
    As you may have noticed in both of these examples for solving a system with Gaussian elimination, to make 
    it easier to manipulate and perform operations on the equations, we made it a practice to keep the 
    variables aligned with each other and then performed the multiplication by scalars and addition of 
    equations using the three "moves" described above.  This helped us make sure we were not accidently 
    adding the coefficients of different variables together.  For the most part, this practice just makes 
    "bookkeeping" easier.  This should sound kind of familiar.  We did the same thing in Chapter 1 when we 
    introduced vectors and matrices.  We viewed these arrays of elements as an easier way to keep track of 
    corresponding components that represented values for the same type of quantities (e.g. orders of the same 
    product, price of the same product, revenue from the same company) without needing to label them.  So the 
    natural question is, do we need to write the variable name if we already know which variable is associated 
    with which column in our "stacked" representation of the equations?  The answer is a resounding, no!  So 
    let's consider what would happen if we were to forego the writing of the variable names.
  </p>
  
  
</subsubsection>

<subsubsection xml:id="stripping-variables">
  <title>Augmented Matrices and Stripping Away Variable Names</title>
  <p>
    When we look at the general structure we have been using for our equations in the Guassian elimination 
    process, we wanted our equations to be of the form, <m>5x_1+3x_2+2x_3=-7</m>, where the variables are 
    all on the left side of the equation and the right side contains only a numerical value.  If we assume this 
    structure for our equations, we can define them in the following way.
  </p>

  <definition xml:id="def-linear-equations">
    <statement>
      <p>
        A <term>linear equation</term> in the variables, <m>x_1, x_2, x_3, \ldots, x_n</m> may be written in 
        the form <m>a_1x_1+a_2x_2+a_3x_3+\cdots+a_nx_n=b</m> where the real numbers represented by 
        <m>a_1,a_2,\ldots,a_n</m> are called <term>coefficients</term> and <m>b</m> is a constant real number.
      </p>
      <p>
        When we have several such equations that share common variables, we say that it is a 
        <term>system of linear equations</term> or, more simply, a <term>linear system</term>.
      </p>
    </statement>
  </definition>
  
  <p>
    Recall from <xref ref="subsec-model-moving-worlds"/>, we began by looking at systems of equations from 
    the standpoint of transformations.
  </p>
  <me>
    \begin{bmatrix}
    14\amp 9\amp 34\amp 41\\
    32\amp 7\amp 12\amp 52\\
    21\amp 8\amp 5\amp 23
    \end{bmatrix}

    \begin{bmatrix}
    p_1\\p_2\\p_3\\p_4
    \end{bmatrix} = 
    \begin{bmatrix}
    r_1\\r_2\\r_3
    \end{bmatrix}
    \Rightarrow
    \begin{array} 3
      14\cdot p_1 + 9\cdot p_2 + 34\cdot p_3 + 41\cdot p_4 =r_1 \\
      32\cdot p_1 + 7\cdot p_2 + 12\cdot p_3 + 52\cdot p_4 =r_2 \\
      21\cdot p_1 + 8\cdot p_2 + 5\cdot p_3 + 23\cdot p_4 =r_3
    \end{array}
  </me>
  <p>
    Here we are separating out the variable names into a single vector and the <em>coefficients</em> are 
    isolated into a matrix.  If you wanted to give a name to this matrix, you might call it...you guessed it, 
    a <term>coefficient matrix</term>.
  </p>
  <p>
    <activity xml:id="convert-equations-matrix-trans">
      <title>From Equations to Matrix Transformation</title>
      <introduction>
        <p>
          Consider the following system of equations.
        </p>
        <p>
          <me>
            \begin{array} 3
            x_1-2x_2+x_3=5 \\
            2x_1+3x_2-2x_3=-17 \\
            3x_1+4x_2+x_3=-5
            \end{array}
          </me>
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            Express this system of equations as a <em>coefficient matrix</em> multiplied by a <m>3\times1</m> 
            vector that is equal to another <m>3\times1</m> vector.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
            Use your <term>System of Equations</term> command on your CAS to solve this system for 
            <m>x_1</m>, <m>x_2</m>, and <m>x_3</m>.
          </p>
        </statement>
      </task>

      <task>
        <statement>
          <p>
            Use the solutions you found in part (b) to show that the matrix-vector equation you created in 
            part (a) is true by multiplying your coefficient matrix by the vector made up of the components 
            from your solutions.
          </p>
        </statement>
      </task>
      
      
    </activity>
  </p>

  <p>
    In the last activity, you took a system of equations and converted it into a coefficient matrix, a 
    vector whose components represented the variables, and another vector whose components represented the 
    values from the right-hand side of the equations.  From Chapter 1, we viewed these equations as transformations 
    and in this section we used Gaussian elimination to find solutions for the variables in the equations (see 
    <xref ref="find-scalars" /> and <xref ref="solve-3by3-system"/>).  
    So how are these connected?  Think back to our use of Gaussian elimination.  What did we really 
    manipulate?  We kept the variables aligned for convenience and multiplied entire equations by scalar values 
    and from time to time added equations together.  However, the only things we really changed in the process 
    were the <em>values</em> of the coefficients (the very things that become isloated in the coefficient 
    matrix in our transformation version of the equations).  So the natural question is, why do we waste our 
    time writing down the variable names if we are just going to keep them aligned anyway.  Instead, why 
    don't we simply work with the numerical values of the coefficients?
  </p>
  <p>
    To enable us to more easily work with the solution process, we can tweak our <em>coefficient matrix</em> 
    just a bit, so that the numerical values from the right-hand side of our equations (which do change as we 
    manipilate) are also included.  We can simply <em>augment</em> our coefficient matrix with these values.  
    Consider the system of equations given below.  We can use the processes of scaling equations and adding them 
    together like in <xref ref="convert-equations-matrix-trans" /> to try and simplify the system to find 
    solutions.
  </p>
  <p>
    <me>
      \begin{array} 3
      x_1 + 2x_2 + 4x_3 =5 \\
      4x_1 + 5x_2 + 4x_3 =2 \\
      2x_1 + 4x_2 + 5x_3 =4
      \end{array}
    </me>
  </p>
  <p>
    In this case we can create the coefficient matrix and then <term>augment</term> it with an additional 
    column containing the values from the right-hand side of the equations.  In this case we get 
  </p>
  <p>
    <me>
      \left[
      \begin{array}{ccc|c}
      1 \amp 2 \amp 4 \amp 5 \\
      4 \amp 5 \amp 4 \amp 2 \\
      2 \amp 4 \amp 5 \amp 4
      \end{array}
      \right]
    </me>
  </p>
  <p>
    Once we have reduced the equations to an <term>augmented matrix</term> with the coefficients on the left 
    side of the bar and the numerical values from the right side of the equations on the right side of the bar, 
    we can use the process we used earlier to operate on the matrix and reduce it to a simplified form.  
    Recall that before, we wanted to eliminate variables so that we could get an equation with just one variable 
    in it.  Here we will do the same, but instead, we wish to manipulate the matrix so that we have entries that 
    are zero in locations (this is like eliminating the variable from that particular equation).  Note that the 
    rows represent equations and the columns represent the variables, <m>x_1</m>, <m>x_2</m>, and <m>x_3</m>, 
    respectively.
  </p>
  <p>
    Suppose we want to eliminate the variable, <m>x_1</m>, from the second row (equation).  As we did 
    earlier, we can multiply the first row (equation) by <m>-4</m> and add it to the second row and use the 
    new resulting row (equation) to replace the old version of the second row.  This would give us the 
    following.
  </p>
  <p>
    <me>
      \left[
      \begin{array}{ccc|c}
      1 \amp 2 \amp 4 \amp 5 \\
      4 \amp 5 \amp 4 \amp 2 \\
      2 \amp 4 \amp 5 \amp 4
      \end{array}
      \right]
      \overset{-4R_1+R_2 \rightarrow R_2}{\longrightarrow}
      \left[
      \begin{array}{ccc|c}
      1 \amp 2 \amp 4 \amp 5 \\
      0 \amp -3 \amp -12 \amp -18 \\
      2 \amp 4 \amp 5 \amp 4
      \end{array}
      \right]
    </me>
  </p>
  <p>
    This can also be done step-by-step on most basic graphing calculators.  In this case, the first entry in the 
    <m>\mathbf{mRowAdd}</m> command is the scalar (-4), followed by the matrix, then the row that is being 
    scaled (row 1), and finally the row that is being added to and thus <m>\mathbf{replaced}</m> (row 3).
  </p>
  <p>
    <image source="images/nspire-system-stage1.png" width="50%">
      <shortdescription>Using CAS Stage 1</shortdescription>
    </image>
  </p>
  <p>
    Now we can do the same thing for the third row multiplying Row 1 by <m>-2</m> and adding it to Row 3 and 
    replacing Row 3 with the result.
  </p>
  <p>
    <me>
      \left[
      \begin{array}{ccc|c}
      1 \amp 2 \amp 4 \amp 5 \\
      0 \amp -3 \amp -12 \amp -18 \\
      2 \amp 4 \amp 5 \amp 4
      \end{array}
      \right]
      \overset{-2R_1+R_3 \rightarrow R_3}{\longrightarrow}
      \left[
      \begin{array}{ccc|c}
      1 \amp 2 \amp 4 \amp 5 \\
      0 \amp -3 \amp -12 \amp -18 \\
      0 \amp 0 \amp -3 \amp -6
      \end{array}
      \right]
    </me>
  </p>
  <p>
    <image source="images/nspire-system-stage2.png" width="50%">
      <shortdescription>Using CAS Stage 1</shortdescription>
    </image>
  </p>
  <p>
    At this point, we can begin to back-solve since the last row represents an equation that contains only 
    the variable <m>x_3</m>.  Once we have this value, we can use it in <m>R_2</m> since it now has entries 
    representing <m>x_2</m> and <m>x_3</m> and inserting our value for <m>x_3</m> leaves just <m>x_2</m>.  
    Finally, we then use the values we have obtained for <m>x_2</m> and <m>x_3</m> in the first row to get 
    our value for <m>x_1</m>.
  </p>
    
  <p>
    From this version of the augmented matrix, we can see that <m>-3x_3=-6</m> and so <m>x_3=2</m>.  As a result, 
    we can see that <m>-3x_2-12\cdot2=-18</m> and so <m>x_2+4\cdot2=6 \Rightarrow x_2=6-8=-2</m>.  Using the 
    first row with these values gives us  <m>x_1+2\cdot-2+4\cdot2=5 \Rightarrow x_1-4+8=5</m>.  This results 
    in <m>x_1=5+4-8=1</m>.
  </p>

  <p>
    The fact that our matrix has zeros in the lower left that enable us to easily 
    back-solve means that this kind of matrix is special and thus deserves a special name.  We refer to this 
    structure of a matrix as <term>upper triangular</term> since the nonzero values of the coefficient matrix 
    portion of the augmented matrix form a triangle.
  </p>

  <p>
    If we want, we could make our back-solving easier by scaling the last two rows.  If we multiply both 
    the second and third rows by <m>-\frac{1}{3}</m>, we get 
  </p>
  <p>
    <me>
    \left[
      \begin{array}{ccc|c}
      1 \amp 2 \amp 4 \amp 5 \\
      0 \amp 1 \amp 4 \amp 6 \\
      0 \amp 0 \amp 1 \amp 2
      \end{array}
      \right]
    </me>
  </p>
  <p>
    Here the <m>\mathbf{mRow}</m> command first takes the scalar, followed by the matrix and then the row that 
    is being scaled.
  </p>
  <p>
    <sidebyside width="45%">
      <image source="images/nspire-system-stage3.png">
      </image>
      <image source="images/nspire-system-stage4.png">
      </image>
    </sidebyside>
  </p>
  <p>
    From this version of the augmented matrix, we can more easily see that <m>x_3=2</m>.  As a result, we can see 
    that <m>x_2+4\cdot2=6</m> and so <m>x_2=6-8=-2</m>.  Using the first row with these values gives us 
    <m>x_1+2\cdot-2+4\cdot2=5 \Rightarrow x_1-4+8=5</m>.  This results in <m>x_1=1</m>.  
  </p>
  <p>
    You may notice that we can continue to use these manipulation processes to further reduce this matrix so 
    that the "back-solve" process will be even easier.  For example, wouldn't it be great if we could get the 
    matrix into the form
    <me>
      \left[
        \begin{array}{ccc|c}
        1 \amp 0 \amp 0 \amp 1 \\
        0 \amp 1 \amp 0 \amp -2 \\
        0 \amp 0 \amp 1 \amp 2
        \end{array}
        \right]
      </me>
      where we can easily read off the solutions since each row has a 1 in the position of a different variable 
      and zeros everywhere else (i.e. no other substitutions to make)?  We will address this later in this section.
  </p>

  <p>
    <activity xml:id="system-solve-upper-triangular">
      <introduction>
        <p>
          Consider the following system of equations.
          <me>
            \begin{array} 3
            x_1 + x_2 + 2x_3 =7 \\
            2x_1 - x_2 + x_3 =5 \\
            4x_1 - 2x_2 + 3x_3 =12
            \end{array}
          </me>
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            Convert the system of equations into an augmented matrix.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Use Gaussian Elimination to reduce your augmented matrix to one that is in upper triangular form.  
            Be sure to indicate your process at each stage by using notation such as 
            <m>\overset{5R_1+R_3 \rightarrow R_3}{\longrightarrow}</m> or 
            <m>\overset{R_1 \leftrightarrow R_3}{\longrightarrow}</m>.  Feel free to use technology 
            (e.g. <m>\mathbf{mRowAdd}</m> command) to perform the arithmetic, but make sure to show your 
            stages in the reduction process.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            After you have solved for one of the values of the unknowns, back-solve to find the remaining unknown 
            values.
          </p>
        </statement>
      </task>
    </activity>
  </p>

  <p>
    Now that we have converted a system of equations to augmented matrix form and then used the process of 
    Gaussian elimination to reduce the system and find solutions, we might ask the question, will we always be 
    able to reduce the matrix to a nice upper triangular form where back-solving to obtain a unique solution 
    is possible?  As you will recall, not all linear combinations of vectors (and thus systems) end with a 
    unique solution.  This means that it will not always be able to find a unique solution to a given system of 
    equations and thus get a nice upper triangular matrix.  If you have taken a formal linear algebra course, 
    you may recall that we can use the form of a matrix for linear systems to determine whether or not the 
    solution(s) is (are) unique, infinite, or non-existent by simplying looking at a reduced version of the 
    matrix.
  </p>
  

  
</subsubsection>


  
</subsection>

</section>